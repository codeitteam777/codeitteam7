{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b19fc7c8",
   "metadata": {},
   "source": [
    "# 베이스라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e27411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Phase 1] 데이터 통합 및 정제 시작 ---\n",
      "총 4526개의 JSON 어노테이션 파일 검색\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "통합 중 (Phase 1): 100%|██████████| 4526/4526 [00:00<00:00, 11989.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 1489개의 이미지 데이터 통합 완료 (정제 전)\n",
      "총 73개의 고유 클래스 발견\n",
      "\n",
      "EDA 기반 오류 파일 17개 제거 시작\n",
      "총 17개의 오류 파일을 master_data에서 삭제\n",
      "최종 정제된 master_data 개수: 1472개 (1472개여야 함)\n",
      "파일 저장 완료: C:\\Users\\daboi\\Desktop\\ai05-level1-project\\train_master_annotations_clean.json\n",
      "파일 저장 완료: C:\\Users\\daboi\\Desktop\\ai05-level1-project\\class_to_id.json\n",
      "--- [Phase 1] 완료 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import shutil # [Phase 2]를 위해 추가\n",
    "\n",
    "print(\"--- [Phase 1] 데이터 통합 및 정제 시작 ---\")\n",
    "\n",
    "# 경로 설정\n",
    "base_dir = r\"C:\\Users\\daboi\\Desktop\\ai05-level1-project\"\n",
    "train_img_dir = os.path.join(base_dir, \"train_images\")\n",
    "train_ann_dir = os.path.join(base_dir, \"train_annotations\")\n",
    "\n",
    "# 모든 JSON 파일 검색\n",
    "json_files = glob.glob(os.path.join(train_ann_dir, \"**\", \"*.json\"), recursive=True)\n",
    "print(f\"총 {len(json_files)}개의 JSON 어노테이션 파일 검색\")\n",
    "\n",
    "# 데이터 통합 (1489개 이미지)\n",
    "master_data = defaultdict(lambda: {\n",
    "    'image_path': '', \n",
    "    'width': 0, \n",
    "    'height': 0, \n",
    "    'annotations': []\n",
    "})\n",
    "\n",
    "class_to_id = {} # YOLO 학습용 ID (0, 1, 2...)\n",
    "current_id = 0\n",
    "processing_errors = 0\n",
    "\n",
    "for json_path in tqdm(json_files, desc=\"통합 중 (Phase 1)\"):\n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        img_info = data['images'][0]\n",
    "        img_filename = img_info['file_name']\n",
    "\n",
    "        if not master_data[img_filename]['image_path']:\n",
    "            image_path = os.path.join(train_img_dir, img_filename)\n",
    "            master_data[img_filename]['image_path'] = image_path\n",
    "            master_data[img_filename]['width'] = img_info['width']\n",
    "            master_data[img_filename]['height'] = img_info['height']\n",
    "\n",
    "        category_map = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "\n",
    "        for ann in data['annotations']:\n",
    "            bbox = ann['bbox'] # [x, y, w, h]\n",
    "            ann_cat_id = ann['category_id']\n",
    "            \n",
    "            if ann_cat_id not in category_map:\n",
    "                processing_errors += 1\n",
    "                continue\n",
    "\n",
    "            class_name = category_map[ann_cat_id]\n",
    "\n",
    "            if class_name not in class_to_id:\n",
    "                class_to_id[class_name] = current_id\n",
    "                current_id += 1\n",
    "                \n",
    "            class_id = class_to_id[class_name]\n",
    "\n",
    "            master_data[img_filename]['annotations'].append({\n",
    "                'class_id': class_id,\n",
    "                'class_name': class_name,\n",
    "                'bbox': bbox\n",
    "            })\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "print(f\"총 {len(master_data)}개의 이미지 데이터 통합 완료 (정제 전)\")\n",
    "print(f\"총 {len(class_to_id)}개의 고유 클래스 발견\")\n",
    "\n",
    "# 오류 데이터 제거 (17개 파일)\n",
    "print(\"\\nEDA 기반 오류 파일 17개 제거 시작\")\n",
    "iou_error_files = [\n",
    "    \"K-003351-018147-020238_0_2_0_2_90_000_200.png\", \n",
    "    \"K-003483-027733-030308-036637_0_2_0_2_90_000_200.png\",\n",
    "    \"K-003351-020238-031863_0_2_0_2_70_000_200.png\", \n",
    "    \"K-003351-029667-031863_0_2_0_2_70_000_200.png\",\n",
    "    \"K-003483-019861-025367-029667_0_2_0_2_90_000_200.png\", \n",
    "    \"K-002483-003743-012081-019552_0_2_0_2_90_000_200.png\",\n",
    "    \"K-003483-019861-020238-031885_0_2_0_2_70_000_200.png\", \n",
    "    \"K-003351-003832-029667_0_2_0_2_90_000_200.png\",\n",
    "    \"K-001900-016548-019607-033009_0_2_0_2_70_000_200.png\"\n",
    "]\n",
    "oob_error_files = [\n",
    "    \"K-003351-016262-018357_0_2_0_2_75_000_200.png\",\n",
    "    \"K-003544-004543-012247-016551_0_2_0_2_70_000_200.png\"\n",
    "]\n",
    "nexium_suspect_images = [\n",
    "    'K-001900-010224-016551-031705_0_2_0_2_70_000_200.png', \n",
    "    'K-001900-010224-016551-031705_0_2_0_2_75_000_200.png',\n",
    "    'K-001900-010224-016551-031705_0_2_0_2_90_000_200.png', \n",
    "    'K-001900-010224-016551-033009_0_2_0_2_70_000_200.png',\n",
    "    'K-001900-010224-016551-033009_0_2_0_2_75_000_200.png', \n",
    "    'K-001900-010224-016551-033009_0_2_0_2_90_000_200.png'\n",
    "]\n",
    "files_to_delete = set(iou_error_files + oob_error_files + nexium_suspect_images)\n",
    "\n",
    "deleted_count = 0\n",
    "# 원본 master_data의 복사본을 순회 (순회 중 원본 삭제를 위해)\n",
    "for filename in list(master_data.keys()):\n",
    "    if filename in files_to_delete:\n",
    "        del master_data[filename]\n",
    "        deleted_count += 1\n",
    "\n",
    "print(f\"총 {deleted_count}개의 오류 파일을 master_data에서 삭제\")\n",
    "print(f\"최종 정제된 master_data 개수: {len(master_data)}개 (1472개여야 함)\")\n",
    "\n",
    "\n",
    "# 최종 산출물 저장\n",
    "# 정제된 1472개 데이터\n",
    "clean_master_path = os.path.join(base_dir, \"train_master_annotations_clean.json\")\n",
    "with open(clean_master_path, \"w\", encoding='utf-8') as f:\n",
    "    json.dump(master_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 클래스 ID 맵\n",
    "class_map_path = os.path.join(base_dir, \"class_to_id.json\")\n",
    "with open(class_map_path, \"w\", encoding='utf-8') as f:\n",
    "    json.dump(class_to_id, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"파일 저장 완료: {clean_master_path}\")\n",
    "print(f\"파일 저장 완료: {class_map_path}\")\n",
    "print(\"--- [Phase 1] 완료 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257c3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 데이터셋 경로: C:\\Users\\daboi\\Desktop\\ai05-level1-project\\CombinedDataset3\n",
      "data.yaml 경로: C:\\Users\\daboi\\Desktop\\ai05-level1-project\\CombinedDataset3\\data_70_15_15_split.yaml\n",
      "==================================================\n",
      "\n",
      "[YOLOv8n] '1단계: Baseline 모델' 학습 시작\n",
      "목표: Valid mAP75 기준 점수 확보\n",
      "==================================================\n",
      "Ultralytics 8.3.222  Python-3.11.14 torch-2.10.0.dev20251029+cu130 CUDA:0 (NVIDIA GeForce RTX 5070, 12227MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\daboi\\Desktop\\ai05-level1-project\\CombinedDataset3\\data_70_15_15_split.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_n_baseline_SGD_lr01, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\Users\\daboi\\Desktop\\ai05-level1-project\\Exp, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\daboi\\Desktop\\ai05-level1-project\\Exp\\yolo_n_baseline_SGD_lr01, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=73\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    837205  ultralytics.nn.modules.head.Detect           [73, [64, 128, 256]]          \n",
      "Model summary: 129 layers, 3,096,741 parameters, 3,096,725 gradients, 8.6 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 경로 설정\n",
    "base_dir = r\"C:\\Users\\daboi\\Desktop\\ai05-level1-project\"\n",
    "combined_dataset_dir = os.path.join(base_dir, \"CombinedDataset3\")\n",
    "yaml_path_combined = os.path.join(combined_dataset_dir, 'data_70_15_15_split.yaml')\n",
    "exp_dir = os.path.join(base_dir, \"Exp\")\n",
    "class_to_id_path = os.path.join(base_dir, \"class_to_id.json\")\n",
    "\n",
    "# 파일 존재 여부 확인\n",
    "if not os.path.exists(class_to_id_path):\n",
    "    print(f\"오류: class_to_id.json 파일을 찾을 수 없음\")\n",
    "    exit()\n",
    "if not os.path.exists(yaml_path_combined):\n",
    "    print(f\"오류: data_70_15_15_split.yaml 파일을 찾을 수 없음\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Combined 데이터셋 경로: {combined_dataset_dir}\")\n",
    "print(f\"data.yaml 경로: {yaml_path_combined}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Baseline 모델 학습\n",
    "print(\"\\n[YOLOv8n] '1단계: Baseline 모델' 학습 시작\")\n",
    "print(\"목표: Valid mAP75 기준 점수 확보\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "results = model.train(\n",
    "    data=yaml_path_combined,\n",
    "    epochs=150,\n",
    "    patience=30,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0,\n",
    "    project=exp_dir,\n",
    "    name='yolo_n_baseline_SGD_lr01', \n",
    "    exist_ok=True,\n",
    "    optimizer='SGD', \n",
    "    lr0=0.01, \n",
    "    augment=True, \n",
    "    workers=0\n",
    ")\n",
    "\n",
    "# 학습 완료 후 최종 mAP75 확인\n",
    "print(\"\\n'1단계: Baseline' 학습 완료\")\n",
    "\n",
    "# ❗️ 이 섹션이 학습이 \"모두 끝난 후\" 자동 실행되어\n",
    "# ❗️ 'best.pt' 모델의 \"최종 점수\"를 출력합니다.\n",
    "print(\"\\n최종 검증 수행\")\n",
    "best_model_path = os.path.join(exp_dir, 'yolo_n_baseline_SGD_lr01', 'weights', 'best.pt')\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    print(f\"'{best_model_path}' 에서 best.pt 모델을 로드\")\n",
    "    best_model = YOLO(best_model_path)\n",
    "    \n",
    "    # best.pt 모델로 'val' 데이터셋에 대한 최종 평가 실행\n",
    "    val_results = best_model.val(\n",
    "        data=yaml_path_combined,\n",
    "        split='val',\n",
    "        verbose=True  # True로 설정하여 모든 평가 지표가 콘솔에 보이도록 함\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"최종 검증 결과 (Best Model)\")\n",
    "    print(f\"mAP50: {val_results.box.map50:.4f}\")\n",
    "    print(f\"mAP75: {val_results.box.map75:.4f}\")  # 팀 규칙에 필요한 최종 점수\n",
    "    print(f\"mAP50-95: {val_results.box.map:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    print(f\"오류: 최적 모델 가중치 '{best_model_path}'를 찾을 수 없습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_env_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
